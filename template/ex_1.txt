# https://sqoop.apache.org/docs/1.4.7/SqoopUserGuide.html

# Connect to a remote MySQL database and import the employee table into HDFS and Hive
# Hostname: clouderaprep.codpf0ubutke.eu-west-1.rds.amazonaws.com
# Database: employees
# Table name: employees
# Username: username
# Password: password

# Import as text file 
# Import using '##' as delimiter
sqoop import 
--connect jdbc:mysql://<hostname>/<database>  
--username --password 
--table  
--target-dir
--fiel...
--as...

---------------------------------------- OTHER EXAMPLES -------------------------------------------

# Simple import, no delimiter speceified and no file type
sqoop import 
--connect jdbc:mysql://<hostname>/<database>  
--username --password 
--table  
--target-dir 

# Import as textfile using query specific conditions
--connect  
--username  --password 
--query 'SELECT FROM WHERE $CONDITIONS' 
--split-by # Split by column
--target-dir  
--as-textfile
--null-non-string '' # The string to be written for a null value for non-string columns
-m # parallelism
# Conditions provide parallelism. You must use split-by too.

sqoop import hive table directly
--connect   
--hive-import
--hive-table 
--username  --password 
--query '' 
--split-by emp_no
--target-dir 
--as-textfile
--null-non-string '' 